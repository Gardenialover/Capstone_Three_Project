{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5557bad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikeras scikit-learn-intelex threadpoolctl -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d5b506-c8b0-43c1-82a1-401081ff6f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import os\n",
    "# import re\n",
    "# from __future__ import print_function\n",
    "from datetime import datetime\n",
    "\n",
    "# import string\n",
    "# import spacy\n",
    "# import nltk\n",
    "# from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold,GridSearchCV\n",
    "\n",
    "import tensorflow as tf   \n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OrdinalEncoder\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from tensorflow.python.keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense,Dropout\n",
    "from scikeras.wrappers import  KerasClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix, f1_score,precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6ba258-515e-41a3-b16d-9b5195e28a5b",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c16a278-9ad1-4367-b7ba-76afd30b32ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/drug_review_clean.csv', index_col= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b0c3ba-bcef-48cf-ae52-06bdcd91edf7",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001d50cd-c601-40d2-a5c6-753711b50e4f",
   "metadata": {},
   "source": [
    "# Build a class to do preprocess\n",
    "The dataframe contains different types of features: numericals ('mean_word_len','word_count', etc), categorical(eg.'rating_category','condidition','drugName'), and datetime ('date'). Also, The target of 'sentiment_label' is categorimcal. The preprocess including the following steps:\n",
    "\n",
    "1.tokenizer the'review_clean' using keras Tokenizer\n",
    "2. encode the categorical features and target 'sentiment_label'\n",
    "3. extract the 'date' to several new features 'year','month','day'.\n",
    "4.scale the numerical features using MinMaxScaler.\n",
    "5. train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d30aa8-af29-492f-a147-1127415d5e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, max_sequence_length=214):\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.tokenizer = None\n",
    "    \"\"\" define a function to convert text to tokenizer \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        self.tokenizer = Tokenizer(num_words = 5000, lower = False)\n",
    "        self.tokenizer.fit_on_texts(X)\n",
    "        return self\n",
    "    \"\"\" define a function to convert the review text into sequence \"\"\"\n",
    "\n",
    "    def transform(self, X):\n",
    "        sequences = self.tokenizer.texts_to_sequences(X)\n",
    "        return pad_sequences(sequences, maxlen= 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c185dd86-2e26-4c8b-a5c7-ace9e7f2e7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumericalScaler(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.scaler.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8efbb86-8378-4357-bca0-6e325ec2d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.ordinal_encoder = OrdinalEncoder()\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        \n",
    "        self.ordinal_encoder.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        return self.ordinal_encoder.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0988a32b-62e7-43da-aa5e-f47ca543abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        X['date'] = pd.to_datetime(X['date'])\n",
    "        X['year'] = X['date'].dt.year\n",
    "        X['month'] = X['date'].dt.month\n",
    "        X['day'] = X['date'].dt.day\n",
    "        return X[['year','month','day']]             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b32e279-10f2-427a-a9bd-1e5f11dc1d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\n",
    "    [\n",
    "        \"drugName\",\n",
    "        \"condition\",\n",
    "        \"rating\",\n",
    "        \"date\",\n",
    "        \"usefulCount\",\n",
    "        \"rating_category\",\n",
    "        \"review_clean\",\n",
    "        \"review_len\",\n",
    "        \"mean_sentence_len\",\n",
    "        \"word_count\",\n",
    "        \"mean_word_len\",\n",
    "        \"unique_word_count\",\n",
    "        \"sentiment_subjectivity\",\n",
    "        \"sentiment_score\",\n",
    "        \"genuine_positive\",\n",
    "        \"genuine_negative\",\n",
    "        \"genuine_neutral\",\n",
    "    ]\n",
    "]\n",
    "y = df[[\"sentiment_label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bcf4d7-51b9-4992-a142-6d0beaa58350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfrom each feature\n",
    "df[\"review_clean\"] = df[\"review_clean\"].apply(lambda x: \" \".join(x.split()[:200]))\n",
    "X_text = TextPreprocessor(max_sequence_length=214).fit_transform(df[\"review_clean\"])\n",
    "numerical_cols = [\n",
    "    \"rating\",\n",
    "    \"usefulCount\",\n",
    "    \"review_len\",\n",
    "    \"mean_sentence_len\",\n",
    "    \"word_count\",\n",
    "    \"mean_word_len\",\n",
    "    \"unique_word_count\",\n",
    "    \"sentiment_subjectivity\",\n",
    "    \"sentiment_score\",\n",
    "]\n",
    "X_numerical = NumericalScaler().fit_transform(df[numerical_cols])\n",
    "X_drugName = CategoricalEncoder().fit_transform(df[[\"drugName\"]])\n",
    "X_condition = CategoricalEncoder().fit_transform(df[[\"condition\"]])\n",
    "X_date = DateExtractor().fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cdb27f-1867-4f63-bf7d-8f9a4e91ee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the features\n",
    "X_transformed = np.concatenate([X_text, X_numerical, X_drugName,\n",
    "                                X_condition, X_date], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768cf371-6528-49c5-99e9-62aedfe69fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode targe feature\n",
    "sentiment_label_encode = LabelEncoder()\n",
    "y_encode = sentiment_label_encode.fit_transform(df['sentiment_label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f71d93-6bfb-40f1-b3f6-a384226123c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_transformed, y_encode, test_size=0.25, random_state=123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3444bc-c4b3-490e-972e-0cd4470e620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "unique_labels= np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=unique_labels, y=y_train)\n",
    "class_weight_dict = dict(zip(unique_labels, class_weights))\n",
    "for label, weight in class_weight_dict.items():\n",
    "    print(f'Class:{label}, weight:{weight:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b6791a-4246-4d17-8361-6d75b5adeb99",
   "metadata": {},
   "source": [
    "There weight for postive sentiment (class1) is 3.15, for negtive is 0.53(class 2) and for neutral is 1.26(class 0). This imbalance will be addressed during modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3b2246-dfda-42d0-8914-cbdde93e7122",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c387d20e-83e2-433e-a067-42b87727b423",
   "metadata": {},
   "source": [
    "\n",
    "The objective of the model is to predict sentiment accurately while mitigating bias. The datased isimbalanced with more positve sentiments. Employing accuracy as the primary metric may lead to misleading conclusiions. To avoid this.  The F1 score will serve as the principle metric. Meanwhile, metrics such as traning time, preciison, recall and accuracy scale for each model will be recored. The chosen model will ideally strikes a balance between predictive performance, computational efficiency and the ability to capture sentiment in drug review.\n",
    "\n",
    "Three models will be exlpored in this sentiment analysis task:\n",
    "\n",
    "1. Multinomial Naive Bayes(MNB)\n",
    "   it is a probalilistic classification algorithm based on Bayes therem and it is widely used in processing text data.  it assumes independence between features. the simlicity and efficiency make it a great baseline model for text based sentiment analysis taks.\n",
    "\n",
    "2. Long short term memory(LSTM)\n",
    "  This is a type of recurrent neural network RNN designed for sequential data propressing. For sentiment analysis, LSTM excels   in capturing dependencies and nuances in text information over extended sequences. Its abaility to retain and forget information  makes it well suited for tasks  where context plays a crucial role, e.g undersing sentiment in long text.\n",
    "3. Random Forest (RF)\n",
    "   It is an effective ensemble learning method in classification. It can provide feature importances, which can help extend the understanding  of model process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679a7274-c9b5-43e3-b584-6ea9d78092d3",
   "metadata": {},
   "source": [
    "## Model Metrics Comparision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aad8ce-7cab-4e3e-999b-8e18f0c4b433",
   "metadata": {},
   "source": [
    "build a method to evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13081e8-a269-431d-952c-340b7becbfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list =[]\n",
    "pd.DataFrame(columns = ['model', 'accuracy', 'precision','recall','F1 score'])\n",
    "\n",
    "def model_metrics(model, y_true, y_pred, best_params = None):\n",
    "    f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average=\"macro\")\n",
    "    recall = recall_score(y_true, y_pred, average=\"macro\")\n",
    "    print(f\"\\n model performance:\")\n",
    "    if best_params:\n",
    "        print(f\"Best hyperparameters: {best_params}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "\n",
    "    \n",
    "    metrics_list.append({'model': model,\n",
    "                                'accuracy':accuracy,\n",
    "                                'precision': precision,\n",
    "                                'recall': recall,\n",
    "                                'F1-score':f1,\n",
    "                                })\n",
    "\n",
    "    print(f'\\n {model} Classification Report:')\n",
    "    print(classification_report(y_true, y_pred))\n",
    "   \n",
    "    \"\"\"plot comfusion matrix\"\"\"\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=[\"class 0 neutral\", \"class 1 positive\", \"class 2 negative\"],\n",
    "        yticklabels=[\"class 0\", \"class 1\", \"class 2\"],\n",
    "    )\n",
    "    plt.xlabel(\"predicted Labels\")\n",
    "    plt.ylabel(\"actual labels\")\n",
    "    plt.title(f\"confusion matrix \")\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5a969b-6a08-4071-ade0-c161fee5f6aa",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes Model (MNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e805c23d-fcbe-4124-a760-17442eeb80c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_model = MultinomialNB()\n",
    "mnb_param_grid = {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0, ],\n",
    "          'fit_prior': [True, False]\n",
    "         }\n",
    "mnb_grid = RandomizedSearchCV(mnb_model, param_distributions=mnb_param_grid, n_jobs=-1, cv=5, verbose=1)\n",
    "\n",
    "print(\"MNB Start Time\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "mnb_grid.fit(X_train,y_train)\n",
    "print(\"MNB End Time =\", datetime.now().strftime(\"%H:%M:%S\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40005e6-a02b-4025-aa50-9322e93c5bfd",
   "metadata": {},
   "source": [
    "MNB shows a fast training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f5bbad-5cfb-4cea-bcce-006912ee11fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mnb_params = mnb_grid.best_params_\n",
    "y_mnb_pred = mnb_grid.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f617a55a-0258-40a8-9214-9658c5a0602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics(mnb_grid.best_estimator_, y_test, y_mnb_pred, best_mnb_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f801939",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726d9c73-a646-4e17-a05b-bc3db281d78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf =  RandomForestClassifier()\n",
    "random_grid = {\n",
    "               'max_depth': [5, 10],\n",
    "               'max_features': ['log2','sqrt', None],\n",
    "               'min_samples_leaf': [4, 8],\n",
    "               'n_estimators': [25, 50]}\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 2, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "from datetime import datetime\n",
    "print(\"Start Time =\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "rf_random_result = rf_random.fit(\n",
    "    X_train, y_train\n",
    ")\n",
    "print(\"End Time =\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "\n",
    "best_rf_params = rf_random.best_params_\n",
    "best_rf_model = rf_random.best_estimator_\n",
    "\n",
    "y_rf_pred = best_rf_model.predict(X_test).round() \n",
    "model_metrics(best_rf_model, y_test, y_rf_pred, best_rf_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78e1d3a-a5ea-4576-a6fb-e99311430086",
   "metadata": {},
   "source": [
    "## LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c95932-98d1-4183-b46d-c280c17455e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a LSTM sequential model\n",
    "def create_lstm_model(dropout_rate=0, epochs=5, batch_size=32):\n",
    "    lstm_model = tf.keras.models.Sequential()\n",
    "    lstm_model.add(Embedding(input_dim=5000, output_dim=32, input_length=214))\n",
    "    lstm_model.add(LSTM(100))\n",
    "    lstm_model.add(Dropout(0.2))\n",
    "    lstm_model.add(Dense(3, activation=\"softmax\"))\n",
    "    lstm_model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    lstm_model.summary()\n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16ee574-df63-4b43-acd9-686a62927f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=123)\n",
    "lstm_model = KerasClassifier(\n",
    "    model=create_lstm_model, dropout_rate=None, epochs=1, batch_size=None, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f25dd9d-7722-42d0-9b23-093a82581357",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperameter tunning\n",
    "param_grids = {\n",
    "    'dropout_rate': [0.0, 0.2],\n",
    "    'epochs': [5,10],\n",
    "    'batch_size': [32, 64],\n",
    "    'class_weight': [class_weight_dict]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51becf2-e6eb-4b67-90f7-2cc817a4566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=123)\n",
    "#model metrics\n",
    "scorers = {\n",
    "            'f1_score': make_scorer(f1_score, average='macro'),\n",
    "            'precision_score': make_scorer(precision_score, average='macro'),\n",
    "            'recall_score': make_scorer(recall_score, average='macro'),\n",
    "            'accuracy_score': make_scorer(accuracy_score)\n",
    "          }\n",
    "\n",
    "lstm_grid = RandomizedSearchCV(\n",
    "    estimator=lstm_model,\n",
    "    param_distributions=param_grids,\n",
    "    cv=kfold,\n",
    "    scoring = scorers,\n",
    "    verbose=1, error_score='raise',n_jobs=-1, refit='f1_score'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c194f456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "print(\"Start Time =\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "lstm_grid_result = lstm_grid.fit(\n",
    "    X_train, y_train, batch_size=None,\n",
    "    epochs=3,\n",
    "    verbose=1,\n",
    "   \n",
    ")\n",
    "print(\"End Time =\", datetime.now().strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed9c7fd-bc21-4ea0-b7c7-a97b3caa20e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lstm_params = lstm_grid.best_params_\n",
    "best_lstm_model = lstm_grid.best_estimator_\n",
    "y_lstm_pred = best_lstm_model.predict(X_test)\n",
    "model_metrics(best_lstm_model, y_test, y_lstm_pred, best_lstm_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d92bab-f402-4326-8308-7a28955b6e83",
   "metadata": {},
   "source": [
    "# Save The Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8add999-fd74-4cc7-910f-b23c400f5cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e33bde-4df1-484e-a2bc-f6aca3d807c8",
   "metadata": {},
   "source": [
    "The RandomForest model is the top performing model with F1 score of 0.99 and a fast training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313bd178-14d9-4bad-bfb3-5af9a49a284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "joblib.dump(best_rf_model, '../Desktop/Capstone_Three_Project/models/best_rf_model.joblib')\n",
    "\n",
    "load_model = joblib.load('best_rf_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772c7278-5a4b-40bc-bc97-5246c940bd66",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a18f1b2-fb7e-49d8-92bc-eee74b286f2b",
   "metadata": {},
   "source": [
    "To build a drug sentiment analysis model, the following preprocessing and model steps were performed:\n",
    "1. Text Tokenization: the 'review' text column was tokenized to break down sentences into individual wrds for analysis. To avoid overfit and reduce training time, only the first 200 word in each review column were used.\n",
    "2. Categorical features ('drugName','condition') encoding. One hot encoding was applied and convert them into a sutable ofrmat for modeling.\n",
    "3. Date feature extraction: 'date', 'year','month' were extracted from the 'date';\n",
    "4. Sentiment encoding: the target feature sentiment was encoded and three sentiment classes were created.\n",
    "5. Numterical featureing scaling: using MinMaxScaler to standardize the range of values.\n",
    "4. Train_test split: The dataset was split into train (0.75), and test(0.25).\n",
    "5. Model exploration: Three models were explored (Multinomial Naive Bayes(MNB), Long Short-Term Memory (LSTM), and Random Forest(RF))\n",
    "6. Model Evaluation: The tuning model performances were assessed. RandomForest emerged as the top performing model with F1 scores reach to over 0.99, and with moderate training time (2.5 mintues).\n",
    "7. Futrue work: The feature importances were not investigated thoroughly. Futre worrk may invole exploring feature importances to gain insigts into  significance fo differenct feature in predicting durg enstiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a3400e-62a1-4890-b454-7cc2676b7acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capstone_Three_Project",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
