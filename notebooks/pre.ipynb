{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45d5b506-c8b0-43c1-82a1-401081ff6f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "from __future__ import print_function\n",
    "from datetime import datetime\n",
    "\n",
    "import string\n",
    "import spacy\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold,GridSearchCV\n",
    "\n",
    "import tensorflow as tf   \n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from tensorflow.python.keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense,Dropout\n",
    "from scikeras.wrappers import  KerasClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix, f1_score,precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6ba258-515e-41a3-b16d-9b5195e28a5b",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c16a278-9ad1-4367-b7ba-76afd30b32ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/drug_review_clean.csv', index_col= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b0c3ba-bcef-48cf-ae52-06bdcd91edf7",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001d50cd-c601-40d2-a5c6-753711b50e4f",
   "metadata": {},
   "source": [
    "# Build a class to do preprocess\n",
    "The dataframe contains different types of features: numericals ('mean_word_len','word_count', etc), categorical(eg.'rating_category','condidition','drugName'), and datetime ('date'). Also, The target of 'sentiment_label' is categorimcal. The preprocess including the following steps:\n",
    "\n",
    "1.tokenizer the'review_clean' using keras Tokenizer\n",
    "2. encode the categorical features and target 'sentiment_label'\n",
    "3. extract the 'date' to several new features 'year','month','day'.\n",
    "4.scale the numerical features using MinMaxScaler.\n",
    "5. train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89d30aa8-af29-492f-a147-1127415d5e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, max_sequence_length=214):\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.tokenizer = None\n",
    "    \"\"\" define a function to convert text to tokenizer \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        self.tokenizer = Tokenizer(num_words = 5000, lower = False)\n",
    "        self.tokenizer.fit_on_texts(X)\n",
    "        return self\n",
    "    \"\"\" define a function to convert the review text into sequence \"\"\"\n",
    "\n",
    "    def transform(self, X):\n",
    "        sequences = self.tokenizer.texts_to_sequences(X)\n",
    "        return pad_sequences(sequences, maxlen= 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c185dd86-2e26-4c8b-a5c7-ace9e7f2e7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumericalScaler(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.scaler.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8efbb86-8378-4357-bca0-6e325ec2d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y = None):\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.label_encoder.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        return self.label_encoder.transform(X).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0988a32b-62e7-43da-aa5e-f47ca543abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        X['date'] = pd.to_datetime(X['date'])\n",
    "        X['year'] = X['date'].dt.year\n",
    "        X['month'] = X['date'].dt.month\n",
    "        X['day'] = X['date'].dt.day\n",
    "        return X[['year','month','day']]               ## should be X[['year','month','day']].values],axis= 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b32e279-10f2-427a-a9bd-1e5f11dc1d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\n",
    "    [\n",
    "        \"drugName\",\n",
    "        \"condition\",\n",
    "        \"rating\",\n",
    "        \"date\",\n",
    "        \"usefulCount\",\n",
    "        \"rating_category\",\n",
    "        \"review_clean\",\n",
    "        \"review_len\",\n",
    "        \"mean_sentence_len\",\n",
    "        \"word_count\",\n",
    "        \"mean_word_len\",\n",
    "        \"unique_word_count\",\n",
    "        \"sentiment_subjectivity\",\n",
    "        \"sentiment_score\",\n",
    "        \"genuine_positive\",\n",
    "        \"genuine_negative\",\n",
    "        \"genuine_neutral\",\n",
    "    ]\n",
    "]\n",
    "y = df[[\"sentiment_label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36bcf4d7-51b9-4992-a142-6d0beaa58350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfrom each feature\n",
    "df[\"review_clean\"] = df[\"review_clean\"].apply(lambda x: \" \".join(x.split()[:200]))\n",
    "X_text = TextPreprocessor(max_sequence_length=214).fit_transform(df[\"review_clean\"])\n",
    "numerical_cols = [\n",
    "    \"rating\",\n",
    "    \"usefulCount\",\n",
    "    \"review_len\",\n",
    "    \"mean_sentence_len\",\n",
    "    \"word_count\",\n",
    "    \"mean_word_len\",\n",
    "    \"unique_word_count\",\n",
    "    \"sentiment_subjectivity\",\n",
    "    \"sentiment_score\",\n",
    "]\n",
    "X_numerical = NumericalScaler().fit_transform(df[numerical_cols])\n",
    "X_drugName = CategoricalEncoder().fit_transform(df[\"drugName\"])\n",
    "X_condition = CategoricalEncoder().fit_transform(df[\"condition\"])\n",
    "X_date = DateExtractor().fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57cdb27f-1867-4f63-bf7d-8f9a4e91ee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the features\n",
    "X_transformed = np.concatenate([X_text, X_numerical, X_drugName,\n",
    "                                X_condition, X_date], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "768cf371-6528-49c5-99e9-62aedfe69fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode targe feature\n",
    "sentiment_label_encode = LabelEncoder()\n",
    "y_encode = sentiment_label_encode.fit_transform(df['sentiment_label'])\n",
    "#y = to_categorical(y_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1f71d93-6bfb-40f1-b3f6-a384226123c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_transformed, y_encode, test_size=0.25, random_state=123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e3444bc-c4b3-490e-972e-0cd4470e620f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:0, weight:1.26\n",
      "Class:1, weight:3.15\n",
      "Class:2, weight:0.53\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "unique_labels= np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=unique_labels, y=y_train)\n",
    "class_weight_dict = dict(zip(unique_labels, class_weights))\n",
    "for label, weight in class_weight_dict.items():\n",
    "    print(f'Class:{label}, weight:{weight:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b6791a-4246-4d17-8361-6d75b5adeb99",
   "metadata": {},
   "source": [
    "There weight for postive sentiment (class1) is 3.15, for negtive is 0.53(class 2) and for neutral is 1.26(class 0). This imbalance will be addressed during modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3b2246-dfda-42d0-8914-cbdde93e7122",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c387d20e-83e2-433e-a067-42b87727b423",
   "metadata": {},
   "source": [
    "\n",
    "The objective of the model is to predict sentiment accurately while mitigating bias. The datased isimbalanced with more positve sentiments. Employiing accuracy as the primary metric may lead to misleading conclusiions. To avoid this.  The F1 score will serve as the principle metric. Meanwhile, metrics such as traning time, preciison, recall and accuracy scale for each model will be recored. The chosen model will ideally strikes a balance between predictive performance, computational efficiency and the ability to capture sentiment in drug review.\n",
    "\n",
    "Three models will be exlpored in this sentiment analysis task:\n",
    "\n",
    "1. Long short term memory(LSTM)\n",
    "This is a type of recurrent neural network RNN designed for sequential data propressing. For sentiment analysis, LSTM excels in capturing dependencies and nuances in text information over extended sequences. Its abaility to retain and forget information  makes it well suited for tasks  where context plays a crucial role, e.g undersing sentiment in long text.\n",
    "\n",
    "2. Support Vector Classification (SVC)\n",
    "   It is a classical maching learning algorithm for multclass classifciation.  it operates by identifying the optimal hyperplance that best separates instances of different classes. Through select kernal, it can enhance the adaptability  and enable to deal with non linear relationships.\n",
    "\n",
    "3. Multinomial Naive Bayes(MNB)\n",
    "   it is a probalilistic classification algorithm based on Bayes therem and it is widely used in processing text data.  it assumes independence between features. the simlicity and efficiency make it a great baseline model for text based sentiment analysis taks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5a969b-6a08-4071-ade0-c161fee5f6aa",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes Model (MNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e805c23d-fcbe-4124-a760-17442eeb80c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB Start Time 23:53:43\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "MNB End Time = 23:53:47\n"
     ]
    }
   ],
   "source": [
    "mnb_model = MultinomialNB()\n",
    "mnb_param_grid = {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0, ],\n",
    "          'fit_prior': [True, False]\n",
    "         }\n",
    "mnb_grid = RandomizedSearchCV(mnb_model, param_distributions=mnb_param_grid, n_jobs=-1, cv=5, verbose=1)\n",
    "\n",
    "print(\"MNB Start Time\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "mnb_grid.fit(X_train,y_train)\n",
    "print(\"MNB End Time =\", datetime.now().strftime(\"%H:%M:%S\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40005e6-a02b-4025-aa50-9322e93c5bfd",
   "metadata": {},
   "source": [
    "MNB shows a fast training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8f5bbad-5cfb-4cea-bcce-006912ee11fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy Through Grid Search : 0.3666\n",
      "Best Parameters : {'fit_prior': True, 'alpha': 10.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Best accuracy Through Grid Search : {:.4f}'.format(mnb_grid.best_score_))\n",
    "print('Best Parameters : {}\\n'.format(mnb_grid.best_params_))\n",
    "mnb_y_pred = mnb_grid.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c06aa1f8-61e8-435d-8e41-8fc4aa84a057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MNB model performance: \n",
      "F1: 0.3512\n",
      "Accuracy: 0.3688\n",
      "Precision: 0.3993\n",
      "Recall: 0.4997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.27      0.28      8321\n",
      "           1       0.21      0.91      0.33      3384\n",
      "           2       0.70      0.32      0.44     20292\n",
      "\n",
      "    accuracy                           0.37     31997\n",
      "   macro avg       0.40      0.50      0.35     31997\n",
      "weighted avg       0.54      0.37      0.39     31997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb_f1 = f1_score(y_test, mnb_y_pred,average='macro')\n",
    "mnb_accuracy = accuracy_score(y_test, mnb_y_pred)\n",
    "mnb_precision = precision_score(y_test, mnb_y_pred,average='macro')\n",
    "mnb_recall = recall_score(y_test, mnb_y_pred,average='macro')\n",
    "\n",
    "print(\"\\n MNB model performance: \")\n",
    "# Print or use the values as needed\n",
    "print(f'F1: {mnb_f1:.4f}')\n",
    "print(f'Accuracy: {mnb_accuracy:.4f}')\n",
    "print(f'Precision: {mnb_precision:.4f}')\n",
    "print(f'Recall: {mnb_recall:.4f}')\n",
    "print(classification_report(y_test, mnb_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78e1d3a-a5ea-4576-a6fb-e99311430086",
   "metadata": {},
   "source": [
    "## LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60c95932-98d1-4183-b46d-c280c17455e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(dropout_rate=0, epochs=5, batch_size=32):\n",
    "    lstm_model = tf.keras.models.Sequential()\n",
    "    lstm_model.add(Embedding(input_dim=5000, output_dim=32, input_length=214))\n",
    "    lstm_model.add(LSTM(100))\n",
    "    lstm_model.add(Dropout(0.2))\n",
    "    lstm_model.add(Dense(3, activation=\"softmax\"))\n",
    "    lstm_model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    lstm_model.summary()\n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fb16831-8d6c-4f68-86be-7d4c42cf4e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list = X_train.tolist()\n",
    "X_test_list = X_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05c0396b-ace9-414e-96de-9cd27e93bd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_preprocessor = TextPreprocessor(max_sequence_length=214)\n",
    "X_text_train = text_preprocessor.fit_transform(X_train_list)\n",
    "X_text_test = text_preprocessor.transform(X_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b464245-ffc3-441f-9143-e5e64f5c2d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add callback to get training and validation metrics for each epoch\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class LossAccCallback(Callback):\n",
    "    def __init__(self):\n",
    "        self.losses = []\n",
    "        self.accuracy = []\n",
    "        self.val_losses = []\n",
    "        self.val_accuracy = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        self.accuracy.append(logs[\"accuracy\"])\n",
    "        self.val_losses.append(logs[\"val_loss\"])\n",
    "        self.val_accuracy.append(logs[\"val_accuracy\"])\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.losses.append(logs['loss'])\n",
    "        self.accuracy.append(logs['accuracy'])\n",
    "        \n",
    "        # Check if 'val_loss' is present in logs before accessing it\n",
    "        if 'val_loss' in logs:\n",
    "            self.val_losses.append(logs['val_loss'])\n",
    "            self.val_accuracy.append(logs['val_accuracy'])\n",
    "            print(f'Epoch {epoch + 1}/{logs[\"epochs\"]} - loss: {logs[\"loss\"]:.4f} - accuracy: {logs[\"accuracy\"]:.4f} - val_loss: {logs[\"val_loss\"]:.4f} - val_accuracy: {logs[\"val_accuracy\"]:.4f}')\n",
    "        else:\n",
    "            print(f'Epoch {epoch + 1}/{logs[\"epochs\"]} - loss: {logs[\"loss\"]:.4f} - accuracy: {logs[\"accuracy\"]:.4f}')\n",
    "\n",
    "\n",
    "        \"\"\"visualize the results\"\"\"\n",
    "\n",
    "    def plot_metrics(self):\n",
    "        epochs = np.arange(1, len(self.losses) + 1)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs, self.val_losses, label=\"validation loss\")\n",
    "        plt.title(\"Training and Validation Loss\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs, self.val_accuracy, label=\"validation accuracy\")\n",
    "        plt.title(\"Training and Validation Accuracy\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f16ee574-df63-4b43-acd9-686a62927f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=123)\n",
    "lstm_model = KerasClassifier(\n",
    "    model=create_lstm_model, dropout_rate=None, epochs=None, batch_size=None, verbose=1, callbacks=[LossAccCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f25dd9d-7722-42d0-9b23-093a82581357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grids = {\n",
    "#     'dropout_rate': [0.0, 0.2, ],\n",
    "#     'epochs': [5,10],\n",
    "#     'batch_size': [32, 64]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "149974c0-29ed-44c3-9b94-a1c865393037",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'dropout_rate': [0.0],\n",
    "    \n",
    "    'batch_size': [32],\n",
    "    'class_weight': [class_weight_dict]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c51becf2-e6eb-4b67-90f7-2cc817a4566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=123)\n",
    "lstm_grid = RandomizedSearchCV(\n",
    "    estimator=lstm_model,\n",
    "    param_distributions=param_grids,\n",
    "    cv=kfold,\n",
    "    scoring='f1',\n",
    "    verbose=1, error_score='raise',n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e65fc0c-bdf8-421b-9d8e-b7a95c593195",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time = 00:09:42\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\Capstone_Three_Project\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\anaconda3\\envs\\Capstone_Three_Project\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\envs\\Capstone_Three_Project\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\envs\\Capstone_Three_Project\\Lib\\site-packages\\joblib\\parallel.py\", line 589, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\envs\\Capstone_Three_Project\\Lib\\site-packages\\joblib\\parallel.py\", line 589, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\envs\\Capstone_Three_Project\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 129, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\envs\\Capstone_Three_Project\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 890, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\ProgramData\\anaconda3\\envs\\Capstone_Three_Project\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1491, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\ProgramData\\anaconda3\\envs\\Capstone_Three_Project\\Lib\\site-packages\\scikeras\\wrappers.py\", line 760, in fit\n    self._fit(\n  File \"C:\\ProgramData\\anaconda3\\envs\\Capstone_Three_Project\\Lib\\site-packages\\scikeras\\wrappers.py\", line 928, in _fit\n    self._fit_keras_model(\n  File \"C:\\ProgramData\\anaconda3\\envs\\Capstone_Three_Project\\Lib\\site-packages\\scikeras\\wrappers.py\", line 505, in _fit_keras_model\n    fit_args[\"epochs\"] = initial_epoch + epochs\n                         ~~~~~~~~~~~~~~^~~~~~~~\nTypeError: unsupported operand type(s) for +: 'int' and 'NoneType'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart Time =\u001b[39m\u001b[38;5;124m\"\u001b[39m, datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m lstm_grid_result \u001b[38;5;241m=\u001b[39m lstm_grid\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      4\u001b[0m     X_train, y_train\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnd Time =\u001b[39m\u001b[38;5;124m\"\u001b[39m, datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Capstone_Three_Project\\Lib\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Capstone_Three_Project\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Capstone_Three_Project\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1914\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1914\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1915\u001b[0m         ParameterSampler(\n\u001b[0;32m   1916\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_distributions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[0;32m   1917\u001b[0m         )\n\u001b[0;32m   1918\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Capstone_Three_Project\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    918\u001b[0m         clone(base_estimator),\n\u001b[0;32m    919\u001b[0m         X,\n\u001b[0;32m    920\u001b[0m         y,\n\u001b[0;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    927\u001b[0m     )\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    931\u001b[0m     )\n\u001b[0;32m    932\u001b[0m )\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Capstone_Three_Project\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Capstone_Three_Project\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Capstone_Three_Project\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Capstone_Three_Project\\Lib\\site-packages\\joblib\\parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1692\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1693\u001b[0m \n\u001b[0;32m   1694\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1697\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1699\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_error_fast()\n\u001b[0;32m   1700\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1702\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Capstone_Three_Project\\Lib\\site-packages\\joblib\\parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1730\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1734\u001b[0m     error_job\u001b[38;5;241m.\u001b[39mget_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Capstone_Three_Project\\Lib\\site-packages\\joblib\\parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    730\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_or_raise()\n\u001b[0;32m    738\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Capstone_Three_Project\\Lib\\site-packages\\joblib\\parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 754\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(\"Start Time =\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "lstm_grid_result = lstm_grid.fit(\n",
    "    X_train, y_train\n",
    ")\n",
    "print(\"End Time =\", datetime.now().strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af122a5f-b01d-4432-8f4c-35bc0985d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lstm_params = lstm_grid_result.best_params_\n",
    "best_lstm_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae14c937-54cf-40c0-b30a-3560bb323e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lstm_model = lstm_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2004bdd9-ee4a-429b-ad48-82e8127d0131",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_lstm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3b5cb0-0c1b-4fc7-86d1-06620f62257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = best_lstm_model.predict(X_test)\n",
    "\n",
    "lstm_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "lstm_accuracy = accuracy_score(y_test, y_pred)\n",
    "lstm_precision = precision_score(y_test, y_pred, average='weighted')\n",
    "lstm_recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"\\n LSTM model performance: \")\n",
    "print(f'best hyperparameters:{best_lstm_params}')\n",
    "# Print or use the values as needed\n",
    "print(f'Accuracy: {lstm_f1:.4f}')\n",
    "print(f'Accuracy: {lstm_accuracy:.4f}')\n",
    "print(f'Precision: {lstm_precision:.4f}')\n",
    "print(f'Recall: {lstm_recall:.4f}')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eec4ba4-41d7-4940-8211-eaf74c02959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_pred)\n",
    "plt.figure(figsize = (8,6))\n",
    "sns.heatmap(cm, annot = True, cmap ='Blues', xticklabels = ['class 0', 'class 1', 'class 2'], yticklabels = ['class 0', 'class 1', 'class 2'])\n",
    "plt.xlabel('predicted Labels')\n",
    "plt.ylabel('actual labels')\n",
    "plt.title('confusion matrix using LSTM modle')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540c18b2-b438-422a-baa6-86b60650305d",
   "metadata": {},
   "source": [
    "Fors LSTM, there is no straightforward feature importance as  in traditional machine learning models.    SHapley Additive explanations (SHAP) to explain the lstm model. it presents how much each input feature contirbutes to the output of a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89671fdc-26ea-41df-9c16-541378fdbeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer= shap.DeepExplainer((lstm_grid.layers[0].input, lstm_grid.layers[-1].output), X_train[:100])\n",
    "# shap_values = explainer.shap_values(X_train)\n",
    "# # # show the  magnitude and direction of featur impact on the output of the model\n",
    "# shap.summary_plot(shap_values, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d234c25-90dd-43fd-b9e6-29ae8f8d3432",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index =0\n",
    "sample_input = X_test[sample_index].reshape(1,-1)\n",
    "shap_values = explainer.shap_values(sample_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a329fb-26b3-4037-bd73-0dfab4e8cc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the attention weights of LSTM\n",
    "from keras.models import Model\n",
    "\n",
    "attention_model = Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942d0ab1-325a-48eb-853c-345cccb8279f",
   "metadata": {},
   "source": [
    "## SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1052966c-9764-45b5-bc23-9a3e667c42fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec1fd63-fb1d-45aa-839d-0aca56479ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_param_grid = {'C': [0.1,1, 10], 'gamma': [1,0.1,0.01],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "# try simple parameters before finallize tunning\n",
    "svc_param_grid = {'C': [0.1], 'gamma': [0.1],'kernel': ['rbf'], 'class_weight' : [class_weight_dict]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ec52c1-a74b-469c-baec-5bbe5915be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=123)\n",
    "svc_grid = RandomizedSearchCV(\n",
    "    estimator=svc_model,\n",
    "    param_distributions=svc_param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=2,\n",
    "    verbose=1,\n",
    "    error_score=\"raise\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "svc_grid_results = svc_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9381d64f-7d7b-41c2-9966-0af9c36ed7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svc_params = svc_grid_result.best_params_\n",
    "best_svc_model = svc_model(**best_lstm_params)\n",
    "best_svc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e4b82f-0f90-4676-a76f-b0799695d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pred = best_svc_model.predict(X_test)\n",
    "svc_accuracy = accuracy_score(y_test, svc_pred)\n",
    "print(\"\\n svc model performance: \")\n",
    "print(f'best hyperparameters:{best_svc_params}')\n",
    "print(f'accuracy:{svc_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d92bab-f402-4326-8308-7a28955b6e83",
   "metadata": {},
   "source": [
    "# Save The Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8add999-fd74-4cc7-910f-b23c400f5cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53ac135-8b6d-4b9b-9098-9bd6dd83ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lstm_model = lstm_grid_result.best_estimator_\n",
    "joblib.dump(best_lstm_model, '../Desktop/Capstone_Three_Project/models/best_lstm_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95118cff-ff26-4a4d-9882-12b062786755",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = joblib.load('best_lstm_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772c7278-5a4b-40bc-bc97-5246c940bd66",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d572db28-0916-4a78-a2e1-8b8ed7b48556",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
