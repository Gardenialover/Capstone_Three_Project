{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c6d1553",
   "metadata": {},
   "source": [
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbde8bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "from __future__ import print_function\n",
    "import inflect\n",
    "import string\n",
    "import spacy\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "import contractions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde23ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the full dataframe for all cells\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c7a1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ_ROOT = os.pardir\n",
    "print(PROJ_ROOT)\n",
    "import sys\n",
    "src_dir = os.path.join(PROJ_ROOT, \"src\")\n",
    "sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6bd3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import TRAIN_FILE_PATH, TEST_FILE_PATH\n",
    "from features.build_features import read_tsv_file\n",
    "train = read_tsv_file(TRAIN_FILE_PATH)\n",
    "test = read_tsv_file(TEST_FILE_PATH)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f7cbe5",
   "metadata": {},
   "source": [
    "join the two datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050a46f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], ignore_index = True)\n",
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dd9bcb",
   "metadata": {},
   "source": [
    "# data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422ccb2f-9a97-4809-838c-ddfd4e5f6c28",
   "metadata": {},
   "source": [
    "2.1 Know the basics of the datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033e2fc0-0da1-49f2-9413-da67b644b88f",
   "metadata": {},
   "source": [
    "1. shape of dataset\n",
    "2. data type\n",
    "3. data distribution\n",
    "4. missing value and the way to handle the missing value\n",
    "5. any duplicates\n",
    "6. any incorrect or manipulated data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c15d364-68c7-49a7-8caf-e81f7dd5765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df.info())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08424e82",
   "metadata": {},
   "source": [
    "there are 1194 missing values in \"condition\", also the data type for rating should be int instead of float, the date should change to time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b8655d-cf61-4485-a764-52713654e20b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['rating'] = df['rating'].astype('int')\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e302da1-b26e-46c4-bf0b-50e69e2542a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.rating.unique())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e510b79-43ed-4d8c-b180-1e31cb990887",
   "metadata": {},
   "source": [
    " There are 10 unique rating from 1 to 10.  The average rating is 6.99, with the 25% to 75% in 5 to 10, suggesing rating is skewed. \n",
    " the mean \"usefulCount\" is 28 while the max can reach to 1291 suggesting the usefulCount is widespread. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1effe1fe-c812-41b7-bbc2-a0fb83b12451",
   "metadata": {},
   "source": [
    "Data cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f77765-c04b-4175-b293-25e1c93b6988",
   "metadata": {},
   "source": [
    "missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0567a804-235c-482d-9579-7c681343d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df[\"condition\"].isna()\n",
    "df[missing_values].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243722cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value_ratio = df.isna().sum()/len(df)*100\n",
    "print(round(missing_value_ratio,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f2c154",
   "metadata": {},
   "source": [
    "only 0.56% missing values, and the review of  it is safe to drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b147aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "print(df.shape)\n",
    "# check duplicate of data\n",
    "print (df.duplicated(subset =[\"review\"]).sum())\n",
    "print (df.duplicated(subset =[\"review\",\"condition\",\"rating\",\"usefulCount\"]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7058aecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_rows = df[df.duplicated(subset=[\"review\",\"condition\",\"rating\",\"usefulCount\"])]\n",
    "duplicate_rows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632f93f9",
   "metadata": {},
   "source": [
    "There are 85420 duplicated in \"reviews\", for each pair of duplicates, they share the same \"condition\", while varied in \"drugname\". Therefore, the duplicate data will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49331645",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=[\"review\",\"condition\",\"rating\",\"usefulCount\"], keep=\"first\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bc2c46",
   "metadata": {},
   "source": [
    "Cleaning \"condition\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38954cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5caad9",
   "metadata": {},
   "source": [
    "some conditions list are comments which can't represent the real conditions, and should be removed form the dataset. Also, some typos such as \"Cance\", \"Disorde\", and incomplete information (e.g \"eve\", which should be \"fever\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caa431e-7406-49c4-94e6-0ed252cb9dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the comments in conditions\n",
    "condition_mask = df.condition.str.contains(\"users found this comment helpful\")\n",
    "df=df[~condition_mask]\n",
    "df.condition.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30be1c6-b63b-457f-9826-f2e80ade8157",
   "metadata": {},
   "outputs": [],
   "source": [
    "repl_dict1 = {\n",
    "    'emale Infertility': 'Female Infertility',\n",
    "    'atigue':'Fatigue',\n",
    "    'Not Listed / Othe': 'Not Listed Other',\n",
    "    'moterol)':'Formoterol Mometasone',\n",
    "    't Pac with Cyclobenzaprine (cyclobenzaprine)':\n",
    "    'Comfort Pac with Cyclobenzaprine',\n",
    "    'zen Shoulde': 'Frozen Shoulder',\n",
    "    'mis': 'Mist',\n",
    "    'tic (mycophenolic acid)': 'Mycophenolic Acid',\n",
    "    'ailure to Thrive': 'Failure To Thrive',\n",
    "    'm Pain Disorde': 'Pain Disorder',\n",
    "    'mist (': 'Mist',\n",
    "    'me': 'Mist',\n",
    "    'lic Acid Deficiency': 'Folic Acid Deficiency',\n",
    "    'min / saxagliptin)': 'Metformin Saxagliptin',\n",
    "    'ge HCT (amlodipine / hydrochlorothiazide / valsartan)':\n",
    "    'Amlodipine Hydrochlorothiazide Valsartan',\n",
    "    'moterol / mometasone)':'Formoterol Mometasone',\n",
    "    'eve':'Fever',\n",
    "    'mance Anxiety':'Performance Anxiety',\n",
    "    'min)':'Metformin Saxagliptin',\n",
    "    'ge (amlodipine / valsartan)':'Amlodipine Valsartan',\n",
    "    'min / rosiglitazone)':'Metformin Rosiglitazone',\n",
    "    'llicular Lymphoma':'Follicular Lymphoma',\n",
    "    'min / pioglitazone)':'Metformin Pioglitazone',\n",
    "    'Pe':\"Performance Anxiety\",\n",
    "    't Care':'Urgent Care',\n",
    "    'llicle Stimulation':'Follicle Stimulation',\n",
    "}\n",
    "\n",
    "df.replace({\"condition\": repl_dict1},inplace=True)\n",
    "repl_dict = {\" Disorde$\":' Disorder', 'Cance$': 'Cancer',' Cance$': ' Cancer',' Tum$':' Tumor', ' Feve$':' Fever',' Ulce$': ' Ulcer', ' Bladde$':' Bladder'}\n",
    "df.replace({\"condition\": repl_dict},regex= True,inplace=True)\n",
    "df.condition.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8ed32c-5e4f-4042-9f0b-1b6cd46f8b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import string\n",
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f94b867-9ece-4b6e-964c-6c704945db16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"condition\"] = df['condition'].apply(remove_punctuations)\n",
    "df.condition.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9451226-d353-4ea1-961f-ddd1ab68a8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_by_condition = df.groupby('condition').agg({'rating':'count'}).sort_values(by ='rating',ascending = False)\n",
    "rating_by_condition = rating_by_condition.nlargest(20, 'rating')\n",
    "# visualize the results\n",
    "plt.figure(figsize =(10,6))\n",
    "rating_by_condition.plot(kind='bar')\n",
    "plt.title('sum of rating by conditions')\n",
    "plt.xlabel('conditions')\n",
    "plt.ylabel('count of rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8daade-33c1-4f26-8d06-5c383379b264",
   "metadata": {},
   "source": [
    "The'birth control', 'depression','pain', 'anxiety' are the conditions have most of rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe97417d-f775-4b38-81d2-4383a8487b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugName_list = df.drugName.unique().tolist()\n",
    "print(len(drugName_list))\n",
    "print(drugName_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4ad793-9b14-413c-8f67-85b9982713a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the most  count drugNme \n",
    "plt.figure(figsize = (10,8))\n",
    "top_drugName = df['drugName'].value_counts(ascending = False).nlargest(20)\n",
    "top_drugName.plot(kind ='bar')\n",
    "plt.title('top 20 counts of drugName')\n",
    "plt.xlabel('Drug Name')\n",
    "plt.ylabel('counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac51c820-f2b3-41ab-919a-e0a764520187",
   "metadata": {},
   "source": [
    "what are the top 10 drugs used in birth contorl?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc1b069-a34f-442e-8387-2879cf466038",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 =df[df['condition'] =='birth control']['drugName'].value_counts()[0:10]\n",
    "d1.plot(kind = 'bar')\n",
    "plt.title('top 10 drugname in birth control ')\n",
    "plt.xlabel('Drug Name')\n",
    "plt.ylabel('counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a938ab39-57cb-4aad-bd84-0b6639d42339",
   "metadata": {},
   "source": [
    "what are the drugs with the highest rating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135423e6-cf00-4000-a462-1d42a647deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_rating_drug = df[df['rating'] == 10]['drugName'].value_counts()\n",
    "#plot the top 10 drug name with rating == 10\n",
    "top_rating_drug[0:10].plot(kind = 'bar')\n",
    "plt.title('top 10 drugname with rating =10 ')\n",
    "plt.xlabel('Drug Name')\n",
    "plt.ylabel('counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda34f6b-fa15-4b94-b82c-d1b9534eec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating'].hist(bins=10)\n",
    "plt.title('histogram of rating in drug review')\n",
    "plt.xlabel(\"rating\")\n",
    "plt.ylabel(\"counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0a1459-c010-4360-987a-f0c950a4ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating_category'] =pd.cut(df['rating'], bins = [1,4,7,10],labels = ['negative','neutral','positive'])\n",
    "print(df['rating_category'].value_counts(normalize = True)*100)\n",
    "\n",
    "df['rating_category'].hist(bins=10)\n",
    "plt.title('histogram of rating in drug review')\n",
    "plt.xlabel(\"rating\")\n",
    "plt.ylabel(\"counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045978c3-129f-468f-b483-627ac171234b",
   "metadata": {},
   "source": [
    "The rating is not eqully distributed, about 70% positive rating, only 17 % and 13% neutral and negative rating. The data is imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62380db-529d-44b8-9a5c-c541120e483f",
   "metadata": {},
   "source": [
    "visulaize the distribution of 'usefulCount'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210e7bb5-9f86-4332-af13-7fb61c0441a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "sns.histplot(df['usefulCount'], kde=True, bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Kernel Density Estimation with Histogram for Useful Count')\n",
    "plt.xlabel('Useful Count')\n",
    "plt.ylabel('Density/Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7625e61-b18e-4892-9e80-f0534293f807",
   "metadata": {},
   "source": [
    "what are the trends of reviews over years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c1896d-de1a-4517-8c44-f316ae223261",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_trend = df['date'].dt.year.value_counts()\n",
    "review_trend.sort_index()\n",
    "sns.barplot(x= review_trend.index, y =review_trend.values,color = 'b').set_title('number of review per year')\n",
    "plt.xlabel('years')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e934126",
   "metadata": {},
   "source": [
    "## cleaning \"review\" and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8de7b5-ceba-4467-a934-c75d4ee7d960",
   "metadata": {},
   "source": [
    "To clean 'review', several steps will performed in a sequence:\n",
    "1. remove_special_characters, especial html encorded one.\n",
    "2. convert number to words\n",
    "3. expand contraction\n",
    "4. remove whitespace\n",
    "5. remove stopwords\n",
    "6. stem and lemmerlize word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b4bee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('&#039', '').replace('\\n','').replace('\\r', '')\n",
    "    text = text.replace(r'[^\\w\\d\\s]',' ')\n",
    "    pattern = re.compile(r'[^a-zA-z0-9\\s]+')\n",
    "    cleaned_text = re.sub(pattern, '', str(text))\n",
    "    cleaned_text =' '.join(word.strip() for word in cleaned_text.split())\n",
    "    return cleaned_text                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f88f84-e39f-40e0-b1d6-d0702f4ec6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import inflect\n",
    "p = inflect.engine()\n",
    "# convert number into words\n",
    "def convert_number(text):\n",
    "    temp_text = text.split()\n",
    "    new_text = []\n",
    "    for word in temp_text:\n",
    "        if word.isdigit():\n",
    "            temp = p.number_to_words(word)\n",
    "            new_text.append(temp)\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    temp_text = ' '.join(new_text)\n",
    "    return temp_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17879762-6568-4d7c-b4ff-05f700893aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(convert_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8c9def-df79-44d3-ab80-da72afb953c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import contractions \n",
    "def expand_contractions(text):\n",
    "    cleaned_text = contractions.fix(text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ae23be-bb62-4133-bbd3-07e45d8fe559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_whitespace(text):\n",
    "    return ' '.join(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d9dd99-25c8-44b5-afa5-d59737e08cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import en_core_web_sm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "nltk.download('stopwords')\n",
    "# from nltk.corpus import stopwords\n",
    "# nlp= spacy.load('en_core_web_sm')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# import nltk\n",
    "nltk.download('punkt')\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    return  ' '.join(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958b8a9a-8cee-4ef1-a620-27d975ade04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_clean'] = df['review'].apply(remove_special_characters)\n",
    "df['review_clean'] = df['review'].apply(convert_number)\n",
    "df['review_clean'] = df['review'].apply(expand_contractions)\n",
    "df['review_clean'] = df['review'].apply(remove_whitespace)\n",
    "df['review_clean'] = df['review'].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f345e3-11bf-49c3-a489-4655ea583daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Snow_ball = nltk.stem.SnowballStemmer(\"english\")\n",
    "df['review_clean'] = df['review_clean'].apply(lambda x: \" \".join(Snow_ball.stem(word) for word in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad81027-2a3d-4035-9853-9c11e0a1885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['review_clean'] = df['review_clean'].apply(lambda x: \" \".join(lemmatizer.lemmatize(word) for word in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9a786c-cf8c-4461-9415-634412d04059",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['review_clean']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0747779d-af03-473e-bbb0-0348565e7509",
   "metadata": {},
   "source": [
    "check the lenth of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b5bf7b-2cd0-4fb7-ae21-8d09edb636b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of words in each review\n",
    "df['word_count'] = df['review_clean'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc97e9-52d9-4db9-9d11-cca43538133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#average lenth of words\n",
    "df[\"mean_word_len\"] = df[\"review_clean\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6af5fa4-cbba-4a6f-82dd-6df4e2d1e0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique word in each review\n",
    "df['unique_word_count'] = df['review_clean'].apply(lambda x: len(set(str(x).split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680b7f90-390d-425a-ab11-eff125455723",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def130c0-d25b-4364-a045-28a788d3943e",
   "metadata": {},
   "source": [
    "Genuine of rating per review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6599e4-8d6f-44e5-b04e-d2cfa7750bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0173903a-b253-4323-8370-d629934050e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to obtain sentiment values\n",
    "def sentiment_score(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b3ca73-3d94-4dea-8ecb-84b4d7bd79b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_subjectivity(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d166eb9b-ef70-45d1-ad49-e27b8cab8477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to label the review in three sentiments: positive, negative and neutral.\n",
    "def sentiment_label(text):\n",
    "    blob =TextBlob(text)\n",
    "    if blob.polarity>0:\n",
    "        return \"positive\"\n",
    "    elif blob.polarity ==0:\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return \"negative\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47147fe-99bf-4c2b-93d8-bdc0b8eeea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_subjectivity'] = df['review_clean'].apply(sentiment_subjectivity)\n",
    "df['sentiment_score'] = df['review_clean'].apply(sentiment_score)\n",
    "df['sentiment_label'] = df['review_clean'].apply(sentiment_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a731578-d011-4e6c-be7e-b04980b0c713",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['sentiment_label'].value_counts())\n",
    "df['sentiment_label'].value_counts().plot(kind ='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7665c38f-22b6-409d-af09-ab6e9e919e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the sentiment_subjectivity distribution\n",
    "sns.kdeplot(df['sentiment_subjectivity'], color='green', fill=True)\n",
    "plt.title('Kernel Density Estimation of sentiment_subjectivity')\n",
    "plt.xlabel('sentiment_subjectivity')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06969e40-c1f3-4d1d-80eb-4a065789ee31",
   "metadata": {},
   "source": [
    "Does the sentiment labels match with the rating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bff0db4-83bc-4d27-b93a-ade261f49a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = df, x = 'rating', y ='sentiment_subjectivity', hue ='sentiment_label')\n",
    "plt.title('Sentiment subjectivity by Rating')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Sentiment subjectivity')\n",
    "# Move the legend to the upper-right corner\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410eff06-3d18-468d-a9a2-01f0ae44bcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = df, x = 'rating', y ='sentiment_score', hue ='sentiment_label')\n",
    "plt.title('Sentiment score by Rating')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Sentiment score')\n",
    "# Move the legend to the upper-right corner\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2772b7f9-a609-4067-96fa-e134f17aef53",
   "metadata": {},
   "source": [
    "The plot shows for each type of sentiments, there are widespread of rating. Below give the way to check the genuine rating of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3af090d-7259-457d-9113-88ed5e077466",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genuine_positive'] = np.where(\n",
    "    (df['rating_category'] == 'positive') &\n",
    "    (df['sentiment_label'] == 'positive') &\n",
    "    (df['sentiment_subjectivity'] <= 0.3),\n",
    "    1,\n",
    "    0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6351d2-df78-4e0d-a385-850d65efa965",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genuine_negative'] = np.where(\n",
    "    (df['rating_category'] == 'negative') &\n",
    "    (df['sentiment_label'] == 'negative') &\n",
    "    (df['sentiment_subjectivity'] <= 0.3),\n",
    "    1,\n",
    "    0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76795565-01ff-4413-964f-312dc22ac819",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genuine_neutral'] = np.where(\n",
    "    (df['rating_category'] == 'neutral') &\n",
    "    (df['sentiment_label'] == 'neutral') &\n",
    "    (df['sentiment_subjectivity'] <= 0.3),\n",
    "    1,\n",
    "    0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075a97bc-d843-4743-bc7c-8501fc18d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461b4dab-dedf-461a-be49-7649a7b54e43",
   "metadata": {},
   "source": [
    "save data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbc6067",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/processed/drug_review_clean.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41f271d-4e66-4519-a1e7-9cd14ef1ec1d",
   "metadata": {},
   "source": [
    "Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18199585-c975-4c5b-a6a2-86eab1f1e329",
   "metadata": {},
   "source": [
    "1.The two raw .tsv data were first loaded and concatted into one dataframe, with a shape of (215063, 7). \n",
    "2.1194 records missing \"condition\" and the missing ratio is 0.56%, they were dropped from the dataset.\n",
    "3.more than 1000 conditions with comments were also removed.\n",
    "4. The condition col has typos, wrong spelling, and was cleaned accordingly using .apply(dictionary)\n",
    "5. Over 85000k duplicated in subset\"review\".The duplicate reviews exhibit variations only in the drug names for the same condition. As a result, only the initial record were retain.\n",
    "6.Visualize the top conditions with rating, top review drugs for birth control.\n",
    "7.clean \"review\" column by several functions including remove_special characters, remove_whitespace, remove_stopwords, expand_contraction, stemming and lemminization. \n",
    "8 new columns such as \"rating_category\",'word_count', 'mean_word_len', 'unique_word_count', 'genuine_positive','genuine_negative','genuine_neutral', 'sentiment_subjectivity','sentiment_score','sentiment_label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee6b4d3-1504-4010-8b67-a4ce6f9bee1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capstone_Three_Project",
   "language": "python",
   "name": "capstone_three_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
