{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c6d1553",
   "metadata": {},
   "source": [
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbde8bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "from __future__ import print_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cde23ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the full dataframe for all cells\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41c7a1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ_ROOT = os.pardir\n",
    "import sys\n",
    "src_dir = os.path.join(PROJ_ROOT, \"src\")\n",
    "sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc6bd3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found, please check the file path.\n",
      "File not found, please check the file path.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m train \u001b[38;5;241m=\u001b[39m read_tsv_file(TRAIN_FILE_PATH)\n\u001b[0;32m      4\u001b[0m test \u001b[38;5;241m=\u001b[39m read_tsv_file(TEST_FILE_PATH)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m, test\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from config import TRAIN_FILE_PATH, TEST_FILE_PATH\n",
    "from features.build_features import read_tsv_file\n",
    "train = read_tsv_file(TRAIN_FILE_PATH)\n",
    "test = read_tsv_file(TEST_FILE_PATH)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce641e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d28773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9f7cbe5",
   "metadata": {},
   "source": [
    "join the two datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050a46f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], ignore_index = True)\n",
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1e9821",
   "metadata": {},
   "source": [
    "Several data wrangling steps need to perform:\n",
    "1. the column names are inconsistant, should all change to lower cases.\n",
    "2. the review contains no words characters, suach as \"&#039\",\"\\r\\n\\r\\n\",\"+\", and capitalize \"YOU SHALL NOT PASS\". They need to clean up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dd9bcb",
   "metadata": {},
   "source": [
    "# data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422ccb2f-9a97-4809-838c-ddfd4e5f6c28",
   "metadata": {},
   "source": [
    "2.1 Know the basics of the datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033e2fc0-0da1-49f2-9413-da67b644b88f",
   "metadata": {},
   "source": [
    "1. shape of dataset\n",
    "2. data type\n",
    "3. data distribution\n",
    "4. missing value and the way to handle the missing value\n",
    "5. any duplicates\n",
    "6. any incorrect or manipulated data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c15d364-68c7-49a7-8caf-e81f7dd5765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df.info())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08424e82",
   "metadata": {},
   "source": [
    "there are 1194 missing values in \"condition\", also the data type for rating should be int instead of float, the date should change to time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b8655d-cf61-4485-a764-52713654e20b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['rating'] = df['rating'].astype('int')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date',inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf77035-54c6-4208-96c1-801f1cf9bbb6",
   "metadata": {},
   "source": [
    "change the unique values of numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e302da1-b26e-46c4-bf0b-50e69e2542a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.rating.unique())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e510b79-43ed-4d8c-b180-1e31cb990887",
   "metadata": {},
   "source": [
    " There are 10 unique rating from 1 to 10.  The average rating is 6.99, with the 25% to 75% in 5 to 10, suggesing rating is skewed. \n",
    " the mean \"usefulCount\" is 28 while the max can reach to 1291 suggesting the usefulCount is widespread. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1effe1fe-c812-41b7-bbc2-a0fb83b12451",
   "metadata": {},
   "source": [
    "Data cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d778d0d4-0b0b-44bb-9ef2-e4463db67754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc90e218-3f8a-4e12-a7a7-4776fb452dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341ffbe9-19d8-44f7-9265-5b927f8a266c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4256ab80-f8b1-4a47-af60-8a3963f74ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99f77765-c04b-4175-b293-25e1c93b6988",
   "metadata": {},
   "source": [
    "missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0567a804-235c-482d-9579-7c681343d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df[\"condition\"].isna()\n",
    "df[missing_values].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243722cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value_ratio = df.isna().sum()/len(df)*100\n",
    "print(round(missing_value_ratio,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f2c154",
   "metadata": {},
   "source": [
    "only 0.56% missing values, and the review of  it is safe to drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b147aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "print(df.shape)\n",
    "# check duplicate of data\n",
    "print (df.duplicated(subset =[\"review\"]).sum())\n",
    "print (df.duplicated(subset =[\"review\",\"condition\",\"rating\",\"usefulCount\"]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7058aecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_rows = df[df.duplicated(subset=[\"review\",\"condition\",\"rating\",\"usefulCount\"])]\n",
    "duplicate_rows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632f93f9",
   "metadata": {},
   "source": [
    "There are 85420 duplicated in \"reviews\", for each pair of duplicates, they share the same \"condition\", while varied in \"drugname\". Therefore, the duplicate data will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49331645",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=[\"review\",\"condition\",\"rating\",\"usefulCount\"], keep=\"first\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dad7bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.set_index(\"date\",inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bc2c46",
   "metadata": {},
   "source": [
    "Cleaning \"condition\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38954cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5caad9",
   "metadata": {},
   "source": [
    "some conditions list are comments which can't represent the real conditions, and should be removed form the dataset. Also, some typos such as \"Cance\", \"Disorde\", and incomplete information (e.g \"eve\", which should be \"fever\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0018ed44-a560-4080-9f75-c66fe590ff5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#remove the comments in conditions\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m condition_mask \u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mcondition\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musers found this comment helpful\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m df\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;241m~\u001b[39mcondition_mask]\n\u001b[0;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#remove the comments in conditions\n",
    "condition_mask =df.condition.str.contains(\"users found this comment helpful\")\n",
    "\n",
    "df=df[~condition_mask]\n",
    "df.shape\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ec70e8-535f-47d6-a5a4-f49e06eb7fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8ed32c-5e4f-4042-9f0b-1b6cd46f8b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text.lower()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f94b867-9ece-4b6e-964c-6c704945db16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"condition\"] = df['condition'].apply(remove_punctuations)\n",
    "df.condition.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27429994-7cb3-4d15-b286-0b7901ea1b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_conditions = {\n",
    "    'emale Infertility': 'Female Infertility',\n",
    "    'atigue':'Fatigue',\n",
    "    'Not Listed / Othe': 'Not Listed Other',\n",
    "    'moterol)':'Formoterol Mometasone',\n",
    "    't Pac with Cyclobenzaprine (cyclobenzaprine)':\n",
    "    'Comfort Pac with Cyclobenzaprine',\n",
    "    'zen Shoulde': 'Frozen Shoulder',\n",
    "    'mis': 'Mist',\n",
    "    'tic (mycophenolic acid)': 'Mycophenolic Acid',\n",
    "    'ailure to Thrive': 'Failure To Thrive',\n",
    "    'm Pain Disorde': 'Pain Disorder',\n",
    "    'mist (': 'Mist',\n",
    "    'me': 'Mist',\n",
    "    'lic Acid Deficiency': 'Folic Acid Deficiency',\n",
    "    'min / saxagliptin)': 'Metformin Saxagliptin',\n",
    "    'ge HCT (amlodipine / hydrochlorothiazide / valsartan)':\n",
    "    'Amlodipine Hydrochlorothiazide Valsartan',\n",
    "    'moterol / mometasone)':'Formoterol Mometasone',\n",
    "    'eve':'Fever',\n",
    "    'mance Anxiety':'Performance Anxiety',\n",
    "    'min)':'Metformin Saxagliptin',\n",
    "    'ge (amlodipine / valsartan)':'Amlodipine Valsartan',\n",
    "    'min / rosiglitazone)':'Metformin Rosiglitazone',\n",
    "    'llicular Lymphoma':'Follicular Lymphoma',\n",
    "    'min / pioglitazone)':'Metformin Pioglitazone',\n",
    "    'Pe':\"Performance Anxiety\",\n",
    "    't Care':'Urgent Care',\n",
    "    'llicle Stimulation':'Follicle Stimulation',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00092e31-be95-4107-a828-37b9a301a887",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({'condition': corrected_conditions}, inplace = True)\n",
    "df.condition.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea834f25-bb83-432a-ac41-c3f2ac767fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "repl_dict = {\" Disorde$\":' Disorder', ' Cance$': 'Cancer',' Tum$':' Tumor', ' Feve$':' Fever',' Ulce$': ' Ulcer'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100441dd-b2eb-4fad-9f97-95f156db1287",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['condition'].replace({k : v for k, v in repl_dict.items()}, \n",
    "                           regex=True)                               \n",
    "df.condition.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadaac68-5823-4d69-bff6-8cf9f19e1e99",
   "metadata": {},
   "source": [
    "how many review per year? how the rating and review change over time, etc.a year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fcfdbe-3755-430a-b6b2-dfda80912bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe97417d-f775-4b38-81d2-4383a8487b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91973618-d961-4fdb-a1fa-2415e50a5103",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d181a6-6126-44f0-ba77-5ffd75e0438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['date'] = pd.to_datetime(df['date'])\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9420ef3-c5a2-49df-b644-06acc21213d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "487499e4-918f-488e-b36e-e5ac91bab0c3",
   "metadata": {},
   "source": [
    "what is the correlation among numeric features?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e934126",
   "metadata": {},
   "source": [
    "## feature engineering and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c96027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #check the text of condition \n",
    "# df[df['condition']=='Tic Disorde']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be120a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbfacab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nlp= spacy.load('en_core_web_sm')\n",
    "#tokenizer = ToktokTokenizer()\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9085dcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions \n",
    "def expand_contractions(text):\n",
    "    cleaned_text = contractions.fix(text)\n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9247e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"&#039;ve been super irritable/moody, and I don&#039;t understand how the side effects can be so extreme for me when I previously was on Nor-Qd \"\n",
    "tx = expand_contractions(raw_text)\n",
    "tx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59bdb96",
   "metadata": {},
   "source": [
    "### remove special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b4bee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_special_characters(text):\n",
    "    text = text.str.lower()\n",
    "    text = text.str.replace('&#039', '').replace('\\n','').replace('\\r', '').replace('/', ' ')\n",
    "    text = text.str.replace(r'[^\\w\\d\\s]',' ')\n",
    "    pattern = re.compile(r'[^a-zA-z0-9\\s]+')\n",
    "    cleaned_text = re.sub(pattern, '', str(text))\n",
    "    cleaned_text =' '.join(word.strip() for word in cleaned_text.split())\n",
    "    return cleaned_text                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84372c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"&#039;ve been super irritable/moody, and I don&#039;t understand how the side effects can be so extreme for me when I previously was on Nor-Qd \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2816d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = remove_special_characters(raw_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5618897-39d7-45bd-8369-0ca9305b0572",
   "metadata": {},
   "source": [
    "what are the top words in review? build a word count plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee599a7-6ffc-406e-ad4b-d60ada7db3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['review'] = df['review'].str.lower()\n",
    "text = df['review'].apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))\n",
    "tokens = word_tokenize(text)\n",
    "count = Counter(tokens)\n",
    "v,counts = zip(count*.most_common(10))\n",
    "plt.bar(v,count)\n",
    "plt.xlabel(\"word\")\n",
    "plt.ylabel(\"counts\")\n",
    "plt.title(\"Top words in drug review\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50f657d-bb5a-43b4-ba5b-2f79f376f15d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4dc3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812c5f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72ebad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbc6067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e4fb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check what are the top conditions.\n",
    "top_conditions = df.condition.value_counts().head(30)\n",
    "top_conditions.plot(kind = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8cc6be",
   "metadata": {},
   "source": [
    "The \"Birth Control\" condition is the highest one, has over 35000 counts, \"Depression\",\"Pain\",\"Anxiety\",\"Acne\",\"Bipolar Disorde\", \"Insomnia\", \"Weight Loss\", \"Obesity\", \"ADHD\" has over 5000 counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2047f859",
   "metadata": {},
   "source": [
    "How many unique drugname?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4a2c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"drugname\"] = df[\"drugname\"].str.title()\n",
    "#check how many drugname\n",
    "drugname_list = df['drugname'].unique().tolist()\n",
    "print(len(drugname_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489e4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the top 30 most reveiwed drug name\n",
    "df.drugname.value_counts().nlargest(30).plot(kind = \"bar\",figsize =(10,6))\n",
    "plt.title(\"The top 30 most reviewed drug name\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73f9439",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rating.value_counts().plot(kind= \"bar\", figsize =(8,6))\n",
    "plt.title(\"the counts of each rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78af82d8",
   "metadata": {},
   "source": [
    "Howm many unique rating values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77791ab4",
   "metadata": {},
   "source": [
    "what's the rating and usefulcount of each condition?, what the distribution of rating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8166fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rating.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ade7e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating'].hist(bins=10)\n",
    "plt.title('histogram of rating in drug review')\n",
    "plt.xlabel(\"rating\")\n",
    "plt.ylabel(\"counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556e106c",
   "metadata": {},
   "source": [
    "the rating indicate the rating either very high (rating 10), or rating very low(at 1), and overall, more positive rating (>=7)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ef14fb",
   "metadata": {},
   "source": [
    "what is the drugname distribution per condition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc65c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('condition').drugname.nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825a8e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 50000\n",
    "chunks = [df[i:i + chunk_size] for i in range(0, len(df), chunk_size)]\n",
    "result = pd.concat([chunk.groupby('condition').agg({'rating':'sum','usefulcount':'sum'}) for chunk in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceed6902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capstone_Three_Project",
   "language": "python",
   "name": "capstone_three_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
